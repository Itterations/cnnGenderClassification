{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c18447",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-20 15:44:20.440488: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-20 15:44:20.440531: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cebed3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/media/tensor/Learning/AI & Machine learning/Deep Learning/Image recoginition male female/Training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1b7a37d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Category =['male','female']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4003e978",
   "metadata": {},
   "source": [
    "# Loading the Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d07095fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 100\n",
    "height = 100\n",
    "\n",
    "img_array = []\n",
    "\n",
    "for category in Category:\n",
    "    path_to_folder = os.path.join(directory,category)\n",
    "    label = Category.index(category)\n",
    "    for img in os.listdir(path_to_folder):\n",
    "        image = cv2.imread(os.path.join(path_to_folder,img))\n",
    "        image = cv2.resize(image, (width,height))\n",
    "        img_array.append([image,label])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a78bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25595732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2178"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e22ea82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2178, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "# Now lets keep the input & respective output ready\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for image, label in img_array:\n",
    "    X.append(image)\n",
    "    Y.append(label)\n",
    "\n",
    "# Conversion in numpy array \n",
    "\n",
    "X = np.array(X)/255.0\n",
    "Y = np.array(Y)/255.0\n",
    "\n",
    "print(X.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df56a2f8",
   "metadata": {},
   "source": [
    "# Now lets Define deep learning Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7cf8454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7b4bc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_40 (Conv2D)          (None, 99, 99, 50)        650       \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 49, 49, 50)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 47, 47, 55)        24805     \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 23, 23, 55)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 21, 21, 60)        29760     \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 10, 10, 60)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 8, 8, 70)          37870     \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 4, 4, 70)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 2, 2, 80)          50480     \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 320)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 720)               231120    \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 2)                 1442      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 376,127\n",
      "Trainable params: 376,127\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model= keras.Sequential()\n",
    "model.add(keras.Input(shape=(100,100,3)))\n",
    "model.add(layers.Conv2D(50,kernel_size=(2,2), padding='valid',activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size= (2,2)))\n",
    "model.add(layers.Conv2D(55,kernel_size=(3,3),padding='valid',activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Conv2D(60,kernel_size=(3,3),padding='valid',activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Conv2D(70,kernel_size=(3,3),padding='valid',activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(layers.Conv2D(80,kernel_size=(3,3),padding='valid',activation='relu'))\n",
    "\n",
    "# above we have built a CNN architacture to extract feature\n",
    "#model.summary()\n",
    "\n",
    "\n",
    "# now we need to pass these extracted features to classifier dense layer but that data should be 1D.\n",
    "\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "\n",
    "model.add(layers.Dense(720,activation=\"relu\"))\n",
    "model.add(layers.Dense(2))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2040bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',optimizer = RMSprop(lr=0.05), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8f550e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "62/62 [==============================] - 29s 454ms/step - loss: 0.0301 - accuracy: 0.4954 - val_loss: 0.0300 - val_accuracy: 0.5046\n",
      "Epoch 2/4\n",
      "62/62 [==============================] - 28s 451ms/step - loss: 0.0300 - accuracy: 0.5041 - val_loss: 0.0300 - val_accuracy: 0.5046\n",
      "Epoch 3/4\n",
      "62/62 [==============================] - 28s 454ms/step - loss: 0.0300 - accuracy: 0.5041 - val_loss: 0.0300 - val_accuracy: 0.5046\n",
      "Epoch 4/4\n",
      "62/62 [==============================] - 28s 453ms/step - loss: 0.0300 - accuracy: 0.5041 - val_loss: 0.0300 - val_accuracy: 0.5046\n"
     ]
    }
   ],
   "source": [
    "model_fit = model.fit(X,Y , epochs = 4, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ef32f0-e7dd-4c41-9590-90e5699ec1e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
